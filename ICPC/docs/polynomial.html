<h1>Polynomial Computation</h1>

<h2>Introduction</h2>

<p>The numerical calculation on polynomials are usually a bunch of technical details put together. Unfortunately, the cp-algorithm template is way too clean and lengthy to use. Luckily, with some understanding, we don't actually need a template for the whole "polynomial" thing, rather some mathematical formula will (hopefully) suffices.</p>

<p>Fortunately, the more complicated ones don't come up often, and most of the time require some crazy level of combinatorics before you reduce to polynomial computation. It is still good to have something to refer to in emergency cases. The definition of the more complicated functions are already very, well, complicated. So we should first go over that.</p>

<h2>Definition</h2>
<p>First, what is a polynomial? Informally, you may know that a polynomial $P$ is an expression in $x$ of the form $a_0 + a_1x + \cdots + a_nx^n$, where $a_n \ne 0$ with the exception of $P = 0$. Of course, this definition is not accurate enough. What if $a_0$ is a vector and $a_1$ is an integer? Then it is not a valid polynomial, since we cannot add vector and integer together! Therefore, we usually impose a condition where $x, a_k$ are all in a field $\mathbb{F}$, where $(\mathbb{F}, +)$ and $(\mathbb{F}, \times)$ are Abelian groups (Identity + Inverse + Associative + Commutative) and distributive laws holds. We denote that as $P \in \mathbb{F}[x]$, which means $P$ is a polynomial in field $\mathbb{F}$ in variable $x$.</p>

<p>That said, every hard algorithm based on fast multiplication of two polynomials, which requires FFT to work on field $\mathbb{F}$. Therefore, there is a high likelyhood that when you need these algorithms, $\mathbb{F} = \mathbb{F}_{998244353}$. Otherwise, there is a 99% chance that you can skip this article.</p>

<p>Alright. In fact, from time to time you will also see "non-ending polynomial": For example, $\frac{1}{1 - x}$ can be seen as the same as $1 + x + x^2 + x^3 + \cdots$, since $(1 - x) (1 + x + x^2 + x^3 + ...) = 1$. Different from "daily math", $1 + x + x^2 + x^3 + \cdots$ can be perfectly well-defined, if we only require that for each power of $x$, we know the coefficient of that power. We don't care whether the value is defined after substituting $x$. Those "non-ending polynomial" are called formal power series, which we denote that as $P = \sum_{k \ge 0} a_k x^k \in \mathbb{F}[[x]]$. </p>

<p>Some notations to make our live easier: Denote degree of $P$ by $\deg P$, which is leading power of $x$ if $P \ne 0$, and $-\infty$ otherwise. We denote also the coefficent of $P$ at $x^n$ by $[x^n] P$.</p>

<p>Let's also introduce some "magical" operations. What is the derivative of $P \in \mathbb{F}[[x]]$? Easy - since $P = \sum_{k \ge 0} a_k x^k \in \mathbb{F}[[x]]$, we have $$ P' = \sum_{k \ge 1} ka_k x^{k-1} $$ By taking derivative for each term. Similarly, integration of $P$ is just $$ \int P(x) \, dx = \sum_{k \ge 0} \frac{a_k}{k + 1} x^{k + 1} $$ Also by integrating terms separately. How about exponential and logarithm? For exponential, we can just apply the formula directly: $$ \exp{P(x)} = \sum_{k \ge 0} \frac{P(x)^k}{k!} $$ Which is valid only when the constant term $[x^0] P \ne 0$. For $\log P$ though, it is simply defined as the inverse of $\exp$, that is, the $Q \in \mathbb{F}[[x]]$ such that $\exp Q = P$. It is defined whenever the constant term $[x^0] P = 1$, since $[x^0] \exp{Q} = 1$ always.</p>

<h2>Newton Iteration Method</h2>
<p>There is a method that we will use multiple times. Let's say we want to solve the equation $F(P) = 0$ where $F, P \in \mathbb{F}[[x]]$. We can think in a "binary lifting" way: If we have $Q_n \in \mathbb{F}[[x]]$ where $F(Q_n) \equiv 0 \pmod{X}$ where $X$ is power of $x$, can we "lift" it up to $Q_{n+1}$ so that $F(Q_{n+1}) \equiv 0 \pmod{X^2}$? Turns out yes most of the time! First of all, we may assume that $Q_{n+1} \equiv Q_n \pmod{X}$, since then $F(Q_{n+1}) \equiv 0 \pmod{X}$ will be satisfied. Also, we have $$ F(Q_{n+1}) - F(Q_n) \equiv \sum_{k \ge 0} a_k (Q_{n+1}^k - Q_n^k) \equiv \sum_{k \ge 1} a_k \cdot k (Q_{n+1} - Q_n) Q_n^{k-1} \equiv F'(Q_n) (Q_{n+1} - Q_n) \pmod{X^2}$$ We want $F(Q_{n+1}) \equiv 0 \pmod{X^2}$, so we simply have $-F(Q_n) \equiv F'(Q_n) (Q_{n+1} - Q_n) \pmod{X^2}$, or $$ Q_{n+1} \equiv Q_n - \frac{F(Q_n)}{F'(Q_n)} \pmod{X^2} $$ Note that you will still have the answer to modulo $x$ to start the iteration.</p>
<h2>Actual Computation</h2>

<p>We shall split the operations into two types: (1) Create new polynomial from known ones, and (2) Conversion between polynomial and set of points. For the sake of simplicity, let's assume $P, Q \in \mathbb{F}[[x]]$ throught this section, and that $\deg P = n$ and $\deg Q = m$.</p>

<h3>I. Create New Functions</h3>

<p>Target: Compute $P \cdot Q$, $P^{-1}$, $P \div Q$, $\gcd(P, Q)$, $P'$, $\int P$, $\log P$, $\exp P$, $P^k$. We usually finds the first $N$ terms of the resulting series. Let's go through these one-by-one.</p>

<ol>
	<li>$P \cdot Q$: $O(N^2)$ naively. $O(N \log N)$ with FFT.</li>
	<li>$P^{-1}$: $O(N^2)$ "naively". $O(N \log N)$ with Newton Iteration: $F(Q) = Q^{-1} - P$ and $F'(Q) = -Q^{-2}$. The recurrence is hence, $$ Q_{n+1} \equiv Q_n - \frac{F(Q_n)}{F'(Q_n)} \equiv Q_n - \frac{Q_n^{-1} - P}{-Q_n^{-2}} \equiv Q_n (2 - P Q_n) \pmod{X^2} $$</li>
	<li>$P \div Q$: $O(N^2)$ naively. $O(N \log N)$ with prequisite $P \cdot Q$ and $P^{-1}$: Define $P^R = x^n P(x^{-1})$, which is reversing $P$ literally. Then, the quotient of $P \div Q$ would exactly be reversed first $n - m + 1$ terms of $P^R \cdot ({Q^R})^{-1}$! Intuitively, when we reverse the polynomials, the "ordinary" division we perceive matches with the division in $\mathbb{F}[[x]]$, which where the terms are calculated in increasing order.</li>
	<li>$\gcd(P, Q)$: $O(N^2)$ with euclidean algorithm, naively. $O(N \log^2 N)$ with half-gcd algorithm, which seems complicated and involve splitting both polynomials into about equal two halves, then recurse downwards.</li>
	<li>$P'$: $O(N)$ "naively", following the definitions.</li>
	<li>$\int P$: $O(N)$ "naively", following the definitions.</li>
	<li>$\log P$: $O(N \log N)$ with prerequisite $P \div Q$: Simply note that $$ (\log P)' = \frac{P'}{P} $$ </li>
	<li>$\exp P$: $O(N \log N)$ with Newton Iteration: $F(Q) = \log Q - P$ and $F'(Q) = Q^{-1}$. The recurrence is hence, $$ Q_{n+1} \equiv Q_n - \frac{F(Q_n)}{F'(Q_n)} \equiv Q_n - \frac{\log Q_n - P}{Q_n^{-1}} \equiv Q_n (1 - \log Q_n + P) \pmod{X^2} $$</li>
	<li>$P^k$: $O(N \log N \log k)$ with binary exponentiation. $O(N \log Nk)$ alternatively, noting $$ P^k = \exp \{k \log P\} $$</li>
</ol>

<h3>II. Point-Set Polynomial Conversion</h3>

<p>Target: (1) Compute $P(x_k)$ for $0 \le k \lt n$ (special case: $x_k = z^k$). (2) Given $\deg P = n - 1$ and $n$ points $(x_k, y_k)$, interpolate $P$.</p>

<p>In fact, both general case can be solved in $O(N \log^2 N)$ in similar segment tree manner. We can always precompute for each segtree node, the product of $x - x_k$ for $k$ over its range, with FFT. Then for (1), we simply traverse the segment tree once, and whenever we go down we take modulo with the computed product.</p>

<p>For Type (2), we can use Lagrange Interpolation in knapsack manners in $O(N^2)$. Alternatively, $$ P = \sum_{k = 1}^{n} \frac{\prod_{j \ne k} (x - x_j)}{\prod_{j \ne k} (x_k - x_j)} \cdot y_k \implies \frac{P}{\prod_{j} (x - x_j)} = \sum_{k = 1}^{n} \frac{y_k} {\prod_{j \ne k} (x_k - x_j)} \cdot \frac{1}{x - x_k} $$ Since $P'(x_k) = \prod_{j \ne k} (x_k - x_j)$, we can carry out a multi-point evaluation on $P'$. We get the form $$P = \sum_{k = 1}^{n} \frac{a_k}{x - x_k}$$ Which we can again use the same segment tree to do some addition of fractions, still in $O(N \log^2 N)$.</p>

<p>Indeed for type (1) there is a special case where $x_k = z^k$. To solve that in $O(N \log N)$, notice that $$ P(z^r) = \sum_{k = 0}^n a_k \cdot z^{kr} = \sum_{k = 0}^n a_k \cdot z^{\binom{k + r}{2} - \binom{k}{2} - \binom{r}{2}} = \frac{1}{z^\binom{r}{2}}\sum_{k = 0}^n a_k \cdot z^{\binom{k + r}{2} - \binom{k}{2}} $$ Therefore, we can simply compute the convolution of $\sum_{k \ge 0} z^{\binom{k}{2}} x^k$ and $\sum_{k = 0}^n a_k z^{-\binom{k}{2}} x^{-k}$, and the coefficient at $x^r$ could be used for computing answer.</p>
