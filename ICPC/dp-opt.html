<!DOCTYPE HTML>
<html>
<head>
	<script src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS_CHTML"></script>
	<script>
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']],
				processEscapes: true
			}
		});
	</script>
	<link rel="stylesheet" type="text/css" href="../index.css">
	<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Ubuntu:regular,bold&subset=Latin">
	<script src="https://code.jquery.com/jquery-3.7.1.js" integrity="sha256-eKhayi8LEQwp4NKxN+CfCh+3qOVUtJn3QNZ0TciWLP4=" crossorigin="anonymous"></script>
	<script src="../function.js"></script>
</head>
<body>

<h1>Dynamic Programming</h1>

<ol>
</ol>

<h2>Introduction</h2>

<p> There are many tutorials on optimising array partition and array merging tasks. Unfortunately I cannot really understand those tutorials so here we are.</p>

<p>In such tasks, normally you are given an array A of length N, and for each subarray A[L : R] (L inclusive, R exclusive), we assign a cost to each of the subarray.</p>

<p>In this article, let's use L -> R to represent the subarray A[L:R], and X[0] -> X[1] -> ... -> X[K] to represent the partition A[X[0]:X[1]], A[X[1]:X[2]], ..., A[X[K-1]:X[K]] for the sake of simplicity. Naturally, for every function f, we can define f(X[0] -> X[1] -> ... X[K]) to be sum of f(X[i] -> X[i+1]) over all i between 0 and K - 1.</p>

<p>The forms of array partition and array merging tasks diverges from here:</p>

<ul>
	<li>Array Partition: If we partition the array A into K subarrays A[X[0]:X[1]], A[X[1]:X[2]], ..., A[X[K-1]:X[K]] where 0 = X[0] < X[1] < ... < X[K] = N, what is the minimum cost C(X[0] -> X[1] -> ... -> X[K])?</li>
	<li>Array Merging: If we can merge two subarrays A[L:M] and A[M:R] together with cost C(L -> R), what is the minimum cost to merge A from A[0], A[1], ..., A[N-1]? </li>
</ul>

<p>For the most "raw" version, both can be computed in $O(N^3)$. Of course, with extra properties, we can do better than this.</p>


<h2>The Basics</h2>

<h3>Array Partition</h3>
<p>Define dp[K][N] be the minimum cost to partition A[:N] into K subarrays. Then dp[K][N] = min{dp[K - 1][M] + C(M -> N)}. Works in $O(N^3)$. </p>

<h3>Array Merging</h3>
<p>Define dp[L][R] be the minimum cost to merge A[L:R]. Then dp[L][R] = min{dp[L][M] + dp[M][R] + C(L -> R)}. Also works in $O(N^3)$.</p>

<h2>Optimal Position</h2>
<p>The above algorithms are slow because we have to loop through all the possible choices to find for the min cost - can we do better if some "magical" condition holds for the optimal position?</p>

<p>For both Array Partition and Array Merging, we can define opt[X][Y] to be the rightmost (or leftmost) optimal M in the transition of dp[X][Y]. When is this "nice"? Well, when opt[X][Y] <= opt[X][Y + 1] or opt[X - 1][Y] <= opt[X][Y], since we expect if our ranges shifts to the right or we have larger number of sets in partition, the optimal position should shifts to the right as well. When these "nice" properties appear, then you can do some standard optimisations.</p>

<p>Note that there are $N^2$ states, so if you decide to compute all states, you cannot do better than $O(N^2)$. </p>

<ul>
	<li>opt[X][Y] <= opt[X][Y + 1]: </li>
</ul>
<h3>opt[X][Y] <= opt[X][Y + 1]</h3>
<h3>Array Partition</h3>

<h2>Quadrangle Inequality</h2>
